# Cross-Level-Requirements-Tracing-Based-on-Large-Language-Model


| 9:1                               |          |           |        |          | 8:2                               |          |           |        |          | 5:5                               |          |           |        |          | 2:8                               |          |           |        |          |
|-----------------------------------|----------|-----------|--------|----------|-----------------------------------|----------|-----------|--------|----------|-----------------------------------|----------|-----------|--------|----------|-----------------------------------|----------|-----------|--------|----------|
| CM1Dataset                        | Accuracy | Precision | Recall | F1_Score | CM1Dataset                        | Accuracy | Precision | Recall | F1_Score | CM1Dataset                        | Accuracy | Precision | Recall | F1_Score | CM1Dataset                        | Accuracy | Precision | Recall | F1_Score |
| 7B-llama                          | 51.69%   | 53.11%    | 45.27% | 48.88%   | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          |
| 7B-llama-Lora                     | 57.98%   | 57.18%    | 57.98% | 57.13%   | 7B-llama-Lora                     | 93.32%   | 93.35%    | 93.32% | 93.25%   | 7B-llama-Lora                     | 58.99%   | 34.80%    | 58.99% | 43.77%   | 7B-llama-Lora                     | 58.99%   | 34.80%    | 58.99% | 43.77%   |
| 7B-llama-P-Tuning                 | 57.14%   | 57.25%    | 57.14% | 56.87%   | 7B-llama-P-Tuning                 | 62.03%   | 38.47%    | 62.03% | 47.49%   | 7B-llama-P-Tuning                 | 52.25%   | 38.26%    | 52.25% | 42.05%   | 7B-llama-P-Tuning                 | 58.99%   | 34.80%    | 58.99% | 43.77%   |
| 7B-llama-PromptTuning             | 86.55%   | 86.55%    | 86.55% | 86.55%   | 7B-llama-PromptTuning             | 84.76%   | 84.54%    | 84.76% | 84.62%   | 7B-llama-PromptTuning             | 76.97%   | 77.60%    | 76.97% | 76.08%   | 7B-llama-PromptTuning             | 64.04%   | 63.25%    | 64.04% | 61.64%   |
| 13B-llama                         | 44.92%   | 66.34%    | 41.64% | 51.16%   | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          |
| 13B-llama-Lora                    | 59.66%   | 35.60%    | 59.66% | 44.59%   | 13B-llama-Lora                    | 58.99%   | 34.80%    | 58.99% | 43.77%   | 13B-llama-Lora                    | 70.87%   | 50.22%    | 70.87% | 58.78%   | 13B-llama-Lora                    | 58.99%   | 34.80%    | 58.99% | 43.77%   |
| 13B-llama-P-Tuning                | 53.78%   | 28.92%    | 53.78% | 37.61%   | 13B-llama-P-Tuning                | 69.84%   | 48.78%    | 69.84% | 57.44%   | 13B-llama-P-Tuning                | 70.87%   | 50.22%    | 70.87% | 70.87%   | 13B-llama-P-Tuning                | 58.99%   | 34.80%    | 58.99% | 43.77%   |
| 13B-llama-PromptTuning            | 61.34%   | 37.63%    | 61.34% | 46.64%   | 13B-llama-PromptTuning            | 62.86%   | 75.65%    | 62.86% | 64.07%   | 13B-llama-PromptTuning            | 74.17%   | 72.31%    | 74.17% | 72.46%   | 13B-llama-PromptTuning            | 67.21%   | 65.15%    | 67.21% | 64.69%   |
| TinyLlama-1.1B-llama              | 56.09%   | 0.93%     | 33.33% | 1.81%    | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          |
| TinyLlama-1.1B-llama-Lora         | 69.44%   | 48.23%    | 69.44% | 56.92%   | TinyLlama-1.1B-llama-Lora         | 65.02%   | 42.28%    | 65.02% | 51.24%   | TinyLlama-1.1B-llama-Lora         | 58.99%   | 34.80%    | 58.99% | 43.77%   | TinyLlama-1.1B-llama-Lora         | 58.99%   | 34.80%    | 58.99% | 43.77%   |
| TinyLlama-1.1B-llama-P-Tuning     | 59.66%   | 35.60%    | 59.66% | 44.59%   | TinyLlama-1.1B-llama-P-Tuning     | 65.02%   | 42.28%    | 65.02% | 51.24%   | TinyLlama-1.1B-llama-P-Tuning     | 58.99%   | 34.80%    | 58.99% | 43.77%   | TinyLlama-1.1B-llama-P-Tuning     | 58.99%   | 34.80%    | 58.99% | 43.77%   |
| TinyLlama-1.1B-llama-PromptTuning | 57.98%   | 33.62%    | 57.98% | 42.56%   | TinyLlama-1.1B-llama-PromptTuning | 65.18%   | 77.32%    | 65.18% | 51.61%   | TinyLlama-1.1B-llama-PromptTuning | 65.17%   | 67.99%    | 65.17% | 59.45%   | TinyLlama-1.1B-llama-PromptTuning | 58.99%   | 34.80%    | 58.99% | 43.77%   |
| ModisDataset                      | Accuracy | Precision | Recall | F1_Score | ModisDataset                      | Accuracy | Precision | Recall | F1_Score | ModisDataset                      | Accuracy | Precision | Recall | F1_Score | ModisDataset                      | Accuracy | Precision | Recall | F1_Score |
| 7B-llama                          | 47.22%   | 81.82%    | 45.76% | 58.70%   | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          |
| 7B-llama-Lora                     | 75.00%   | 75.00%    | 75.00% | 75.00%   | 7B-llama-Lora                     | 74.29%   | 74.41%    | 74.29% | 74.29%   | 7B-llama-Lora                     | 70.00%   | 49.00%    | 70.00% | 57.65%   | 7B-llama-Lora                     | 70.00%   | 49.00%    | 70.00% | 57.65%   |
| 7B-llama-P-Tuning                 | 75.00%   | 82.14%    | 75.00% | 70.83%   | 7B-llama-P-Tuning                 | 48.57%   | 23.59%    | 48.57% | 31.76%   | 7B-llama-P-Tuning                 | 80.00%   | 84.44%    | 80.00% | 76.25%   | 7B-llama-P-Tuning                 | 70.00%   | 49.00%    | 70.00% | 57.65%   |
| 7B-llama-PromptTuning             | 87.50%   | 90.63%    | 87.50% | 89.04%   | 7B-llama-PromptTuning             | 70.00%   | 68.67%    | 70.00% | 68.57%   | 7B-llama-PromptTuning             | 80.00%   | 79.38%    | 80.00% | 78.67%   | 7B-llama-PromptTuning             | 65.00%   | 47.89%    | 65.00% | 55.15%   |
| 13B-llama                         | 45.83%   | 93.94%    | 45.59% | 61.38%   | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          |
| 13B-llama-Lora                    | 75.00%   | 56.25%    | 75.00% | 64.29%   | 13B-llama-Lora                    | 70.00%   | 49.00%    | 70.00% | 57.65%   | 13B-llama-Lora                    | 65.31%   | 42.65%    | 65.31% | 51.60%   | 13B-llama-Lora                    | 75.00%   | 81.58%    | 75.00% | 67.97%   |
| 13B-llama-P-Tuning                | 62.50%   | 39.06%    | 62.50% | 48.08%   | 13B-llama-P-Tuning                | 70.00%   | 49.00%    | 70.00% | 57.65%   | 13B-llama-P-Tuning                | 65.31%   | 42.65%    | 65.31% | 51.60%   | 13B-llama-P-Tuning                | 70.00%   | 49.00%    | 70.00% | 57.65%   |
| 13B-llama-PromptTuning            | 50.00%   | 25.00%    | 50.00% | 33.33%   | 13B-llama-PromptTuning            | 60.00%   | 60.00%    | 60.00% | 60.00%   | 13B-llama-PromptTuning            | 71.43%   | 73.77%    | 71.43% | 65.89%   | 13B-llama-PromptTuning            | 70.00%   | 65.56%    | 70.00% | 64.38%   |
| TinyLlama-1.1B-llama              | 54.17%   | 0.00%     | 0.00%  | 0.00%    | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          |
| TinyLlama-1.1B-llama-Lora         | 62.50%   | 39.06%    | 62.50% | 48.08%   | TinyLlama-1.1B-llama-Lora         | 51.43%   | 26.45%    | 51.43% | 34.93%   | TinyLlama-1.1B-llama-Lora         | 70.00%   | 49.00%    | 70.00% | 57.65%   | TinyLlama-1.1B-llama-Lora         | 70.00%   | 49.00%    | 70.00% | 57.65%   |
| TinyLlama-1.1B-llama-P-Tuning     | 62.50%   | 39.06%    | 62.50% | 48.08%   | TinyLlama-1.1B-llama-P-Tuning     | 89.47%   | 80.06%    | 89.47% | 84.50%   | TinyLlama-1.1B-llama-P-Tuning     | 70.00%   | 49.00%    | 70.00% | 57.65%   | TinyLlama-1.1B-llama-P-Tuning     | 70.00%   | 49.00%    | 70.00% | 57.65%   |
| TinyLlama-1.1B-llama-PromptTuning | 37.50%   | 14.06%    | 37.50% | 20.45%   | TinyLlama-1.1B-llama-PromptTuning | 31.58%   | 75.37%    | 31.58% | 40.31%   | TinyLlama-1.1B-llama-PromptTuning | 70.00%   | 49.00%    | 70.00% | 57.65%   | TinyLlama-1.1B-llama-PromptTuning | 70.00%   | 49.00%    | 70.00% | 57.65%   |
| GANNT                             | Accuracy | Precision | Recall | F1_Score | GANNT                             | Accuracy | Precision | Recall | F1_Score | GANNT                             | Accuracy | Precision | Recall | F1_Score | GANNT                             | Accuracy | Precision | Recall | F1_Score |
| 7B-llama                          | 37.68%   | 80.23%    | 30.80% | 44.52%   | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          |
| 7B-llama-Lora                     | 75.00%   | 56.25%    | 75.00% | 64.29%   | 7B-llama-Lora                     | 80.95%   | 84.70%    | 80.95% | 74.85%   | 7B-llama-Lora                     | 68.29%   | 46.64%    | 68.29% | 55.43%   | 7B-llama-Lora                     | 68.29%   | 46.64%    | 68.29% | 55.43%   |
| 7B-llama-P-Tuning                 | 67.86%   | 46.05%    | 67.86% | 54.86%   | 7B-llama-P-Tuning                 | 56.25%   | 31.64%    | 56.25% | 40.45%   | 7B-llama-P-Tuning                 | 68.29%   | 46.64%    | 68.29% | 55.43%   | 7B-llama-P-Tuning                 | 68.29%   | 46.64%    | 68.29% | 55.43%   |
| 7B-llama-PromptTuning             | 89.29%   | 89.20%    | 89.29% | 89.24%   | 7B-llama-PromptTuning             | 61.70%   | 38.07%    | 61.70% | 47.09%   | 7B-llama-PromptTuning             | 73.17%   | 71.55%    | 73.17% | 71.08%   | 7B-llama-PromptTuning             | 60.98%   | 55.26%    | 60.98% | 57.01%   |
| 13B-llama                         | 31.16%   | 100.00%   | 31.16% | 47.51%   | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          |
| 13B-llama-Lora                    | 67.86%   | 46.05%    | 67.86% | 54.81%   | 13B-llama-Lora                    | 68.29%   | 46.64%    | 68.29% | 55.43%   | 13B-llama-Lora                    | 62.71%   | 39.33%    | 62.71% | 48.34%   | 13B-llama-Lora                    | 68.29%   | 46.64%    | 68.29% | 55.43%   |
| 13B-llama-P-Tuning                | 71.43%   | 51.02%    | 71.43% | 59.52%   | 13B-llama-P-Tuning                | 68.29%   | 46.64%    | 68.29% | 55.43%   | 13B-llama-P-Tuning                | 62.71%   | 39.33%    | 62.71% | 48.34%   | 13B-llama-P-Tuning                | 68.29%   | 46.64%    | 68.29% | 55.43%   |
| 13B-llama-PromptTuning            | 64.29%   | 41.33%    | 64.29% | 50.31%   | 13B-llama-PromptTuning            | 57.45%   | 52.33%    | 57.45% | 52.39%   | 13B-llama-PromptTuning            | 57.63%   | 47.78%    | 57.63% | 49.29%   | 13B-llama-PromptTuning            | 43.90%   | 50.20%    | 43.90% | 45.85%   |
| TinyLlama-1.1B-llama              | 55.43%   | 27.91%    | 28.24% | 28.07%   | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          |
| TinyLlama-1.1B-llama-Lora         | 78.57%   | 83.33%    | 78.57% | 71.87%   | TinyLlama-1.1B-llama-Lora         | 67.50%   | 45.56%    | 67.50% | 54.40%   | TinyLlama-1.1B-llama-Lora         | 68.29%   | 46.64%    | 68.29% | 55.43%   | TinyLlama-1.1B-llama-Lora         | 68.29%   | 46.64%    | 68.29% | 55.43%   |
| TinyLlama-1.1B-llama-P-Tuning     | 75.00%   | 56.25%    | 75.00% | 64.29%   | TinyLlama-1.1B-llama-P-Tuning     | 67.50%   | 45.56%    | 67.50% | 54.40%   | TinyLlama-1.1B-llama-P-Tuning     | 68.29%   | 46.64%    | 68.29% | 55.43%   | TinyLlama-1.1B-llama-P-Tuning     | 68.29%   | 46.64%    | 68.29% | 55.43%   |
| TinyLlama-1.1B-llama-PromptTuning | 64.29%   | 41.33%    | 64.29% | 50.32%   | TinyLlama-1.1B-llama-PromptTuning | 67.50%   | 45.56%    | 67.50% | 54.40%   | TinyLlama-1.1B-llama-PromptTuning | 68.29%   | 46.64%    | 68.29% | 55.43%   | TinyLlama-1.1B-llama-PromptTuning | 68.29%   | 46.64%    | 68.29% | 55.43%   |
| WARC                              | Accuracy | Precision | Recall | F1_Score | WARC                              | Accuracy | Precision | Recall | F1_Score | WARC                              | Accuracy | Precision | Recall | F1_Score | WARC                              | Accuracy | Precision | Recall | F1_Score |
| 7B-llama                          | 51.82%   | 90.00%    | 52.78% | 66.54%   | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          |
| 7B-llama-Lora                     | 61.11%   | 60.75%    | 61.11% | 60.74%   | 7B-llama-Lora                     | 82.63%   | 83.43%    | 82.63% | 82.32%   | 7B-llama-Lora                     | 54.72%   | 53.02%    | 54.72% | 52.61%   | 7B-llama-Lora                     | 43.40%   | 18.83%    | 43.40% | 26.27%   |
| 7B-llama-P-Tuning                 | 66.67%   | 72.22%    | 66.67% | 65.83%   | 7B-llama-P-Tuning                 | 55.09%   | 30.35%    | 55.09% | 39.14%   | 7B-llama-P-Tuning                 | 47.17%   | 49.07%    | 47.17% | 47.02%   | 7B-llama-P-Tuning                 | 43.40%   | 18.83%    | 43.40% | 26.27%   |
| 7B-llama-PromptTuning             | 80.56%   | 81.44%    | 80.56% | 81.00%   | 7B-llama-PromptTuning             | 50.00%   | 50.10%    | 50.00% | 50.00%   | 7B-llama-PromptTuning             | 60.38%   | 59.69%    | 60.38% | 59.49%   | 7B-llama-PromptTuning             | 52.83%   | 59.80%    | 52.83% | 49.87%   |
| 13B-llama                         | 54.34%   | 40.00%    | 60.80% | 48.25%   | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          |
| 13B-llama-Lora                    | 67.86%   | 46.05%    | 67.86% | 54.81%   | 13B-llama-Lora                    | 43.40%   | 18.83%    | 43.40% | 26.27%   | 13B-llama-Lora                    | 57.86%   | 58.29%    | 57.86% | 57.89%   | 13B-llama-Lora                    | 43.40%   | 18.83%    | 43.40% | 26.27%   |
| 13B-llama-P-Tuning                | 71.43%   | 51.02%    | 71.43% | 59.52%   | 13B-llama-P-Tuning                | 51.56%   | 26.59%    | 51.56% | 35.08%   | 13B-llama-P-Tuning                | 45.91%   | 21.50%    | 45.91% | 29.29%   | 13B-llama-P-Tuning                | 56.60%   | 32.04%    | 56.60% | 40.92%   |
| 13B-llama-PromptTuning            | 64.29%   | 41.33%    | 64.29% | 50.31%   | 13B-llama-PromptTuning            | 60.94%   | 62.23%    | 60.94% | 60.33%   | 13B-llama-PromptTuning            | 54.72%   | 55.19%    | 54.72% | 54.73%   | 13B-llama-PromptTuning            | 50.94%   | 51.44%    | 50.94% | 51.12%   |
| TinyLlama-1.1B-llama              | 48.74%   | 6.32%     | 70.59% | 11.59%   | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          |
| TinyLlama-1.1B-llama-Lora         | 41.67%   | 17.36%    | 41.67% | 24.51%   | TinyLlama-1.1B-llama-Lora         | 52.83%   | 27.91%    | 52.83% | 36.52%   | TinyLlama-1.1B-llama-Lora         | 43.40%   | 18.83%    | 43.40% | 26.27%   | TinyLlama-1.1B-llama-Lora         | 43.40%   | 18.83%    | 43.40% | 26.27%   |
| TinyLlama-1.1B-llama-P-Tuning     | 61.11%   | 37.35%    | 61.11% | 46.36%   | TinyLlama-1.1B-llama-P-Tuning     | 52.83%   | 27.91%    | 52.83% | 36.52%   | TinyLlama-1.1B-llama-P-Tuning     | 43.40%   | 18.83%    | 43.40% | 26.27%   | TinyLlama-1.1B-llama-P-Tuning     | 43.40%   | 18.83%    | 43.40% | 26.27%   |
| TinyLlama-1.1B-llama-PromptTuning | 63.89%   | 63.82%    | 63.89% | 63.85%   | TinyLlama-1.1B-llama-PromptTuning | 52.83%   | 27.91%    | 52.83% | 36.52%   | TinyLlama-1.1B-llama-PromptTuning | 43.40%   | 18.83%    | 43.40% | 26.27%   | TinyLlama-1.1B-llama-PromptTuning | 43.40%   | 18.83%    | 43.40% | 26.27%   |
| CCHIT                             | Accuracy | Precision | Recall | F1_Score | CCHIT                             | Accuracy | Precision | Recall | F1_Score | CCHIT                             | Accuracy | Precision | Recall | F1_Score | CCHIT                             | Accuracy | Precision | Recall | F1_Score |
| 7B-llama                          | 48.43%   | 47.86%    | 38.29% | 42.54%   | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          |
| 7B-llama-Lora                     | 55.56%   | 55.56%    | 55.56% | 55.56%   | 7B-llama-Lora                     | 59.23%   | 35.81%    | 59.23% | 44.64%   | 7B-llama-Lora                     | 64.00%   | 77.22%    | 64.00% | 51.85%   | 7B-llama-Lora                     | 62.00%   | 38.44%    | 62.00% | 47.46%   |
| 7B-llama-P-Tuning                 | 50.00%   | 64.40%    | 50.00% | 47.81%   | 7B-llama-P-Tuning                 | 42.42%   | 77.71%    | 42.42% | 31.36%   | 7B-llama-P-Tuning                 | 62.00%   | 38.44%    | 62.00% | 47.46%   | 7B-llama-P-Tuning                 | 62.00%   | 38.44%    | 62.00% | 47.46%   |
| 7B-llama-PromptTuning             | 91.67%   | 92.75%    | 91.67% | 92.21%   | 7B-llama-PromptTuning             | 64.41%   | 64.61%    | 64.41% | 64.49%   | 7B-llama-PromptTuning             | 60.00%   | 57.02%    | 60.00% | 56.95%   | 7B-llama-PromptTuning             | 52.00%   | 52.00%    | 52.00% | 52.00%   |
| 13B-llama                         | 59.83%   | 5.00%     | 46.67% | 9.03%    | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          |
| 13B-llama-Lora                    | 52.78%   | 27.85%    | 52.78% | 36.46%   | 13B-llama-Lora                    | 64.00%   | 77.22%    | 64.00% | 51.85%   | 13B-llama-Lora                    | 61.49%   | 37.81%    | 61.49% | 46.82%   | 13B-llama-Lora                    | 62.00%   | 38.44%    | 62.00% | 47.46%   |
| 13B-llama-P-Tuning                | 55.56%   | 30.86%    | 55.56% | 39.68%   | 13B-llama-P-Tuning                | 42.37%   | 17.95%    | 42.37% | 25.52%   | 13B-llama-P-Tuning                | 38.51%   | 14.83%    | 38.51% | 21.42%   | 13B-llama-P-Tuning                | 62.00%   | 38.44%    | 62.00% | 47.46%   |
| 13B-llama-PromptTuning            | 75.00%   | 74.07%    | 75.00% | 74.53%   | 13B-llama-PromptTuning            | 57.63%   | 56.65%    | 57.63% | 56.72%   | 13B-llama-PromptTuning            | 62.84%   | 61.21%    | 62.84% | 61.17%   | 13B-llama-PromptTuning            | 54.00%   | 50.19%    | 54.00% | 51.14%   |
| TinyLlama-1.1B-llama              | 40.46%   | 39.18%    | 89.29% | 54.46%   | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          |
| TinyLlama-1.1B-llama-Lora         | 69.44%   | 64.70%    | 69.44% | 66.99%   | TinyLlama-1.1B-llama-Lora         | 64.00%   | 40.96%    | 64.00% | 49.95%   | TinyLlama-1.1B-llama-Lora         | 62.00%   | 38.44%    | 62.00% | 47.46%   | TinyLlama-1.1B-llama-Lora         | 62.00%   | 38.44%    | 62.00% | 47.46%   |
| TinyLlama-1.1B-llama-P-Tuning     | 66.67%   | 44.44%    | 66.67% | 53.33%   | TinyLlama-1.1B-llama-P-Tuning     | 64.00%   | 40.96%    | 64.00% | 49.95%   | TinyLlama-1.1B-llama-P-Tuning     | 62.00%   | 38.44%    | 62.00% | 47.46%   | TinyLlama-1.1B-llama-P-Tuning     | 62.00%   | 38.44%    | 62.00% | 47.46%   |
| TinyLlama-1.1B-llama-PromptTuning | 58.33%   | 49.68%    | 58.33% | 53.66%   | TinyLlama-1.1B-llama-PromptTuning | 64.00%   | 40.96%    | 64.00% | 49.95%   | TinyLlama-1.1B-llama-PromptTuning | 62.00%   | 38.44%    | 62.00% | 47.46%   | TinyLlama-1.1B-llama-PromptTuning | 62.00%   | 38.44%    | 62.00% | 47.46%   |
| IP                                | Accuracy | Precision | Recall | F1_Score | IP                                | Accuracy | Precision | Recall | F1_Score | IP                                | Accuracy | Precision | Recall | F1_Score | IP                                | Accuracy | Precision | Recall | F1_Score |
| 7B-llama                          | 60.53%   | 15.73%    | 48.28% | 23.73%   | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          |
| 7B-llama-Lora                     | 69.57%   | 69.36%    | 69.57% | 69.46%   | 7B-llama-Lora                     | 57.14%   | 37.74%    | 57.14% | 45.45%   | 7B-llama-Lora                     | 56.25%   | 31.64%    | 56.25% | 40.50%   | 7B-llama-Lora                     | 56.25%   | 31.64%    | 56.25% | 40.50%   |
| 7B-llama-P-Tuning                 | 65.22%   | 65.22%    | 65.22% | 65.22%   | 7B-llama-P-Tuning                 | 53.33%   | 28.44%    | 53.33% | 37.10%   | 7B-llama-P-Tuning                 | 50.00%   | 30.00%    | 50.00% | 37.50%   | 7B-llama-P-Tuning                 | 56.25%   | 31.64%    | 56.25% | 40.50%   |
| 7B-llama-PromptTuning             | 95.65%   | 95.99%    | 95.65% | 95.82%   | 7B-llama-PromptTuning             | 64.41%   | 64.61%    | 64.41% | 64.49%   | 7B-llama-PromptTuning             | 50.00%   | 50.78%    | 50.00% | 50.20%   | 7B-llama-PromptTuning             | 53.13%   | 54.34%    | 53.13% | 53.26%   |
| 13B-llama                         | 42.11%   | 83.15%    | 38.74% | 52.85%   | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          |
| 13B-llama-Lora                    | 65.22%   | 42.53%    | 65.22% | 51.49%   | 13B-llama-Lora                    | 62.50%   | 66.96%    | 62.50% | 56.16%   | 13B-llama-Lora                    | 50.00%   | 56.18%    | 50.00% | 49.74%   | 13B-llama-Lora                    | 56.25%   | 31.64%    | 56.25% | 40.50%   |
| 13B-llama-P-Tuning                | 39.13%   | 77.87%    | 39.13% | 52.09%   | 13B-llama-P-Tuning                | 43.75%   | 19.14%    | 43.75% | 26.63%   | 13B-llama-P-Tuning                | 50.00%   | 56.18%    | 50.00% | 49.74%   | 13B-llama-P-Tuning                | 46.88%   | 49.43%    | 46.88% | 45.78%   |
| 13B-llama-PromptTuning            | 69.57%   | 69.91%    | 69.57% | 69.74%   | 13B-llama-PromptTuning            | 65.79%   | 62.09%    | 65.79% | 62.79%   | 13B-llama-PromptTuning            | 65.63%   | 64.38%    | 65.63% | 64.09%   | 13B-llama-PromptTuning            | 46.88%   | 46.43%    | 46.88% | 46.61%   |
| TinyLlama-1.1B-llama              | 38.60%   | 38.77%    | 98.88% | 55.70%   | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          |
| TinyLlama-1.1B-llama-Lora         | 56.52%   | 57.68%    | 56.52% | 57.09%   | TinyLlama-1.1B-llama-Lora         | 63.64%   | 40.50%    | 63.64% | 49.49%   | TinyLlama-1.1B-llama-Lora         | 56.25%   | 31.64%    | 56.25% | 40.50%   | TinyLlama-1.1B-llama-Lora         | 58.99%   | 34.80%    | 58.99% | 43.77%   |
| TinyLlama-1.1B-llama-P-Tuning     | 56.52%   | 31.95%    | 56.52% | 40.82%   | TinyLlama-1.1B-llama-P-Tuning     | 63.64%   | 40.50%    | 63.64% | 49.49%   | TinyLlama-1.1B-llama-P-Tuning     | 56.25%   | 31.64%    | 56.25% | 40.50%   | TinyLlama-1.1B-llama-P-Tuning     | 56.25%   | 31.64%    | 56.25% | 40.50%   |
| TinyLlama-1.1B-llama-PromptTuning | 65.22%   | 42.53%    | 65.22% | 51.49%   | TinyLlama-1.1B-llama-PromptTuning | 63.64%   | 40.50%    | 63.64% | 49.49%   | TinyLlama-1.1B-llama-PromptTuning | 56.25%   | 31.64%    | 56.25% | 40.50%   | TinyLlama-1.1B-llama-PromptTuning | 56.25%   | 31.64%    | 56.25% | 40.50%   |
| CM1-Modis                         | Accuracy | Precision | Recall | F1_Score | CM1-Modis                         | Accuracy | Precision | Recall | F1_Score | CM1-Modis                         | Accuracy | Precision | Recall | F1_Score | CM1-Modis                         | Accuracy | Precision | Recall | F1_Score |
| 7B-llama                          | 59.17%   | 20.06%    | 44.63% | 27.68%   | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          |
| 7B-llama-Lora                     | 52.59%   | 50.28%    | 52.59% | 51.41%   | 7B-llama-Lora                     | 93.62%   | 93.69%    | 93.62% | 93.52%   | 7B-llama-Lora                     | 63.56%   | 59.55%    | 63.56% | 59.00%   | 7B-llama-Lora                     | 64.78%   | 41.96%    | 64.78% | 50.93%   |
| 7B-llama-P-Tuning                 | 60.74%   | 61.74%    | 60.74% | 61.24%   | 7B-llama-P-Tuning                 | 64.71%   | 41.87%    | 64.71% | 50.84%   | 7B-llama-P-Tuning                 | 63.16%   | 54.56%    | 63.16% | 53.27%   | 7B-llama-P-Tuning                 | 54.66%   | 55.83%    | 54.66% | 55.16%   |
| 7B-llama-PromptTuning             | 90.37%   | 90.38%    | 90.37% | 90.37%   | 7B-llama-PromptTuning             | 86.88%   | 86.80%    | 86.88% | 86.83%   | 7B-llama-PromptTuning             | 82.19%   | 82.44%    | 82.19% | 81.38%   | 7B-llama-PromptTuning             | 75.30%   | 74.65%    | 75.30% | 74.37%   |
| 13B-llama                         | 41.28%   | 88.45%    | 39.45% | 54.56%   | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          |
| 13B-llama-Lora                    | 62.96%   | 62.83%    | 62.96% | 62.89%   | 13B-llama-Lora                    | 66.40%   | 63.80%    | 66.40% | 61.10%   | 13B-llama-Lora                    | 67.76%   | 45.91%    | 67.76% | 54.73%   | 13B-llama-Lora                    | 64.78%   | 41.96%    | 64.78% | 50.93%   |
| 13B-llama-P-Tuning                | 55.56%   | 54.39%    | 55.56% | 54.97%   | 13B-llama-P-Tuning                | 65.25%   | 42.57%    | 65.25% | 51.53%   | 13B-llama-P-Tuning                | 67.05%   | 61.90%    | 67.05% | 60.59%   | 13B-llama-P-Tuning                | 63.56%   | 57.82%    | 63.56% | 56.00%   |
| 13B-llama-PromptTuning            | 80.00%   | 80.06%    | 80.00% | 80.03%   | 13B-llama-PromptTuning            | 85.82%   | 85.72%    | 85.82% | 85.53%   | 13B-llama-PromptTuning            | 86.93%   | 86.81%    | 86.93% | 86.85%   | 13B-llama-PromptTuning            | 67.21%   | 65.15%    | 67.21% | 64.69%   |
| TinyLlama-1.1B-llama              | 60.43%   | 58.33%    | 2.61%  | 5.00%    | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          |
| TinyLlama-1.1B-llama-Lora         | 81.48%   | 81.49%    | 81.48% | 81.48%   | TinyLlama-1.1B-llama-Lora         | 72.76%   | 52.95%    | 72.76% | 61.29%   | TinyLlama-1.1B-llama-Lora         | 59.90%   | 35.88%    | 59.90% | 44.88%   | TinyLlama-1.1B-llama-Lora         | 59.90%   | 35.88%    | 59.90% | 44.88%   |
| TinyLlama-1.1B-llama-P-Tuning     | 47.41%   | 41.33%    | 47.41% | 44.16%   | TinyLlama-1.1B-llama-P-Tuning     | 72.76%   | 52.95%    | 72.76% | 61.29%   | TinyLlama-1.1B-llama-P-Tuning     | 64.78%   | 41.96%    | 64.78% | 50.93%   | TinyLlama-1.1B-llama-P-Tuning     | 58.99%   | 43.80%    | 58.99% | 43.77%   |
| TinyLlama-1.1B-llama-PromptTuning | 60.00%   | 56.09%    | 60.00% | 57.98%   | TinyLlama-1.1B-llama-PromptTuning | 76.42%   | 74.85%    | 76.42% | 75.16%   | TinyLlama-1.1B-llama-PromptTuning | 59.90%   | 35.88%    | 59.90% | 44.88%   | TinyLlama-1.1B-llama-PromptTuning | 59.90%   | 35.88%    | 59.90% | 44.88%   |
| GANNT-WARC                        | Accuracy | Precision | Recall | F1_Score | GANNT-WARC                        | Accuracy | Precision | Recall | F1_Score | GANNT-WARC                        | Accuracy | Precision | Recall | F1_Score | GANNT-WARC                        | Accuracy | Precision | Recall | F1_Score |
| 7B-llama                          | 38.99%   | 96.47%    | 39.11% | 55.66%   | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          |
| 7B-llama-Lora                     | 63.89%   | 63.88%    | 63.89% | 63.88%   | 7B-llama-Lora                     | 88.21%   | 89.75%    | 88.21% | 87.69%   | 7B-llama-Lora                     | 57.69%   | 58.58%    | 57.69% | 49.10%   | 7B-llama-Lora                     | 55.77%   | 31.10%    | 55.77% | 39.93%   |
| 7B-llama-P-Tuning                 | 88.89%   | 89.01%    | 88.89% | 88.95%   | 7B-llama-P-Tuning                 | 35.48%   | 12.59%    | 35.48% | 18.59%   | 7B-llama-P-Tuning                 | 34.62%   | 34.29%    | 34.62% | 34.44%   | 7B-llama-P-Tuning                 | 55.77%   | 31.10%    | 55.77% | 39.93%   |
| 7B-llama-PromptTuning             | 90.28%   | 91.32%    | 90.28% | 90.80%   | 7B-llama-PromptTuning             | 79.03%   | 79.20%    | 79.03% | 79.09%   | 7B-llama-PromptTuning             | 61.54%   | 61.12%    | 61.54% | 60.16%   | 7B-llama-PromptTuning             | 58.65%   | 58.40%    | 58.65% | 58.48%   |
| 13B-llama                         | 39.97%   | 99.65%    | 39.77% | 56.85%   | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          |
| 13B-llama-Lora                    | 58.33%   | 68.12%    | 58.33% | 62.85%   | 13B-llama-Lora                    | 52.88%   | 48.40%    | 52.88% | 45.88%   | 13B-llama-Lora                    | 60.52%   | 36.62%    | 60.52% | 45.63%   | 13B-llama-Lora                    | 55.77%   | 31.10%    | 55.77% | 39.93%   |
| 13B-llama-P-Tuning                | 60.25%   | 60.28%    | 60.25% | 60.26%   | 13B-llama-P-Tuning                | 34.62%   | 35.41%    | 34.62% | 34.81%   | 13B-llama-P-Tuning                | 60.52%   | 36.62%    | 60.52% | 45.63%   | 13B-llama-P-Tuning                | 55.77%   | 31.10%    | 55.77% | 39.93%   |
| 13B-llama-PromptTuning            | 80.56%   | 80.56%    | 80.56% | 80.56%   | 13B-llama-PromptTuning            | 60.48%   | 60.36%    | 60.48% | 60.42%   | 13B-llama-PromptTuning            | 71.20%   | 70.76%    | 71.20% | 70.20%   | 13B-llama-PromptTuning            | 61.54%   | 61.95%    | 61.54% | 61.65%   |
| TinyLlama-1.1B-llama              | 43.62%   | 39.04%    | 74.91% | 51.33%   | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          |
| TinyLlama-1.1B-llama-Lora         | 80.56%   | 83.38%    | 80.56% | 81.95%   | TinyLlama-1.1B-llama-Lora         | 64.42%   | 41.50%    | 64.42% | 50.48%   | TinyLlama-1.1B-llama-Lora         | 61.29%   | 37.57%    | 61.29% | 46.58%   | TinyLlama-1.1B-llama-Lora         | 61.29%   | 37.57%    | 61.29% | 46.58%   |
| TinyLlama-1.1B-llama-P-Tuning     | 58.33%   | 34.03%    | 58.33% | 42.98%   | TinyLlama-1.1B-llama-P-Tuning     | 64.42%   | 41.50%    | 64.42% | 50.48%   | TinyLlama-1.1B-llama-P-Tuning     | 61.29%   | 37.57%    | 61.29% | 46.58%   | TinyLlama-1.1B-llama-P-Tuning     | 43.01%   | 51.62%    | 43.01% | 38.99%   |
| TinyLlama-1.1B-llama-PromptTuning | 69.44%   | 48.23%    | 69.44% | 56.92%   | TinyLlama-1.1B-llama-PromptTuning | 65.38%   | 64.60%    | 65.38% | 64.90%   | TinyLlama-1.1B-llama-PromptTuning | 61.29%   | 37.57%    | 61.29% | 46.58%   | TinyLlama-1.1B-llama-PromptTuning | 38.71%   | 14.98%    | 38.71% | 21.61%   |
| IP-CCHIT                          | Accuracy | Precision | Recall | F1_Score | IP-CCHIT                          | Accuracy | Precision | Recall | F1_Score | IP-CCHIT                          | Accuracy | Precision | Recall | F1_Score | IP-CCHIT                          | Accuracy | Precision | Recall | F1_Score |
| 7B-llama                          | 48.97%   | 70.00%    | 41.49% | 52.10%   | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          |
| 7B-llama-Lora                     | 77.59%   | 77.74%    | 77.59% | 77.66%   | 7B-llama-Lora                     | 65.56%   | 42.98%    | 65.56% | 51.92%   | 7B-llama-Lora                     | 53.01%   | 53.77%    | 53.01% | 53.01%   | 7B-llama-Lora                     | 54.22%   | 29.39%    | 54.22% | 38.12%   |
| 7B-llama-P-Tuning                 | 53.45%   | 52.89%    | 53.45% | 53.16%   | 7B-llama-P-Tuning                 | 55.56%   | 30.86%    | 55.56% | 39.68%   | 7B-llama-P-Tuning                 | 45.78%   | 20.96%    | 45.78% | 28.76%   | 7B-llama-P-Tuning                 | 50.60%   | 50.50%    | 50.60% | 50.54%   |
| 7B-llama-PromptTuning             | 94.83%   | 94.91%    | 94.83% | 94.84%   | 7B-llama-PromptTuning             | 76.29%   | 76.38%    | 76.29% | 76.32%   | 7B-llama-PromptTuning             | 60.24%   | 60.19%    | 60.24% | 58.65%   | 7B-llama-PromptTuning             | 54.22%   | 53.33%    | 54.22% | 52.62%   |
| 13B-llama                         | 52.24%   | 52.17%    | 41.81% | 46.42%   | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          |
| 13B-llama-Lora                    | 60.34%   | 60.52%    | 60.34% | 60.43%   | 13B-llama-Lora                    | 51.81%   | 50.62%    | 51.81% | 50.12%   | 13B-llama-Lora                    | 57.79%   | 33.39%    | 57.79% | 42.33%   | 13B-llama-Lora                    | 54.22%   | 29.39%    | 54.22% | 38.12%   |
| 13B-llama-P-Tuning                | 63.79%   | 54.38%    | 63.79% | 58.71%   | 13B-llama-P-Tuning                | 42.27%   | 17.87%    | 42.27% | 25.12%   | 13B-llama-P-Tuning                | 57.79%   | 33.39%    | 57.79% | 42.33%   | 13B-llama-P-Tuning                | 54.22%   | 29.39%    | 54.22% | 38.12%   |
| 13B-llama-PromptTuning            | 70.69%   | 71.17%    | 70.69% | 70.93%   | 13B-llama-PromptTuning            | 77.32%   | 77.22%    | 77.32% | 77.24%   | 13B-llama-PromptTuning            | 70.49%   | 73.16%    | 70.49% | 67.81%   | 13B-llama-PromptTuning            | 57.83%   | 58.56%    | 57.83% | 52.97%   |
| TinyLlama-1.1B-llama              | 55.17%   | 41.28%    | 30.87% | 35.32%   | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          |
| TinyLlama-1.1B-llama-Lora         | 79.31%   | 79.59%    | 79.31% | 79.45%   | TinyLlama-1.1B-llama-Lora         | 63.86%   | 40.78%    | 63.86% | 49.77%   | TinyLlama-1.1B-llama-Lora         | 54.22%   | 29.39%    | 54.22% | 38.12%   | TinyLlama-1.1B-llama-Lora         | 54.22%   | 29.39%    | 54.22% | 38.12%   |
| TinyLlama-1.1B-llama-P-Tuning     | 46.55%   | 21.67%    | 46.55% | 29.57%   | TinyLlama-1.1B-llama-P-Tuning     | 63.86%   | 40.78%    | 63.86% | 49.77%   | TinyLlama-1.1B-llama-P-Tuning     | 54.22%   | 29.39%    | 54.22% | 38.12%   | TinyLlama-1.1B-llama-P-Tuning     | 43.37%   | 33.84%    | 43.37% | 29.60%   |
| TinyLlama-1.1B-llama-PromptTuning | 48.27%   | 23.31%    | 48.27% | 31.44%   | TinyLlama-1.1B-llama-PromptTuning | 65.06%   | 62.67%    | 65.06% | 62.14%   | TinyLlama-1.1B-llama-PromptTuning | 54.22%   | 29.39%    | 54.22% | 38.12%   | TinyLlama-1.1B-llama-PromptTuning | 53.01%   | 52.92%    | 53.01% | 52.96%   |
| ALL                               | Accuracy | Precision | Recall | F1_Score | ALL                               | Accuracy | Precision | Recall | F1_Score | ALL                               | Accuracy | Precision | Recall | F1_Score | ALL                               | Accuracy | Precision | Recall | F1_Score |
| 7B-llama                          | 47.11%   | 31.72%    | 33.04% | 32.37%   | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          | 7B-llama                          |          |           |        |          |
| 7B-llama-Lora                     | 60.38%   | 58.50%    | 60.38% | 59.43%   | 7B-llama-Lora                     | 98.13%   | 98.12%    | 98.13% | 98.12%   | 7B-llama-Lora                     | 69.75%   | 68.92%    | 69.75% | 69.09%   | 7B-llama-Lora                     | 62.82%   | 56.46%    | 62.82% | 53.38%   |
| 7B-llama-P-Tuning                 | 75.09%   | 75.17%    | 75.09% | 75.13%   | 7B-llama-P-Tuning                 | 61.80%   | 62.01%    | 61.80% | 61.90%   | 7B-llama-P-Tuning                 | 64.20%   | 65.07%    | 64.20% | 51.47%   | 7B-llama-P-Tuning                 | 36.26%   | 13.15%    | 36.26% | 19.30%   |
| 7B-llama-PromptTuning             | 92.45%   | 92.49%    | 92.45% | 92.47%   | 7B-llama-PromptTuning             | 88.76%   | 88.69%    | 88.76% | 88.70%   | 7B-llama-PromptTuning             | 90.07%   | 90.04%    | 90.07% | 90.05%   | 7B-llama-PromptTuning             | 77.37%   | 77.50%    | 77.37% | 77.43%   |
| 13B-llama                         | 53.95%   | 69.70%    | 45.02% | 54.71%   | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          | 13B-llama                         |          |           |        |          |
| 13B-llama-Lora                    | 66.04%   | 67.39%    | 66.04% | 66.71%   | 13B-llama-Lora                    | 68.13%   | 66.75%    | 68.13% | 64.97%   | 13B-llama-Lora                    | 60.54%   | 58.71%    | 60.54% | 59.22%   | 13B-llama-Lora                    | 63.74%   | 40.63%    | 63.74% | 49.63%   |
| 13B-llama-P-Tuning                | 58.11%   | 55.38%    | 58.11% | 56.71%   | 13B-llama-P-Tuning                | 65.48%   | 68.76%    | 65.48% | 52.57%   | 13B-llama-P-Tuning                | 59.91%   | 55.88%    | 59.91% | 56.25%   | 13B-llama-P-Tuning                | 63.28%   | 59.01%    | 63.28% | 56.77%   |
| 13B-llama-PromptTuning            | 83.77%   | 84.18%    | 83.77% | 83.97%   | 13B-llama-PromptTuning            | 91.12%   | 91.11%    | 91.12% | 91.03%   | 13B-llama-PromptTuning            | 85.16%   | 85.04%    | 85.16% | 84.98%   | 13B-llama-PromptTuning            | 76.44%   | 75.97%    | 76.44% | 75.91%   |
| TinyLlama-1.1B-llama              | 40.05%   | 37.61%    | 76.33% | 50.39%   | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          | TinyLlama-1.1B-llama              |          |           |        |          |
| TinyLlama-1.1B-llama-Lora         | 84.91%   | 85.03%    | 84.91% | 84.97%   | TinyLlama-1.1B-llama-Lora         | 68.66%   | 47.15%    | 68.66% | 55.91%   | TinyLlama-1.1B-llama-Lora         | 60.16%   | 36.20%    | 60.16% | 45.20%   | TinyLlama-1.1B-llama-Lora         | 60.16%   | 36.20%    | 60.16% | 45.20%   |
| TinyLlama-1.1B-llama-P-Tuning     | 41.89%   | 56.08%    | 41.89% | 47.96%   | TinyLlama-1.1B-llama-P-Tuning     | 68.66%   | 47.15%    | 68.66% | 55.91%   | TinyLlama-1.1B-llama-P-Tuning     | 60.16%   | 36.20%    | 60.16% | 45.20%   | TinyLlama-1.1B-llama-P-Tuning     | 60.16%   | 36.20%    | 60.16% | 45.20%   |
| TinyLlama-1.1B-llama-PromptTuning | 60.75%   | 66.27%    | 60.75% | 63.39%   | TinyLlama-1.1B-llama-PromptTuning | 75.12%   | 76.98%    | 75.12% | 75.69%   | TinyLlama-1.1B-llama-PromptTuning | 60.16%   | 36.20%    | 60.16% | 45.20%   | TinyLlama-1.1B-llama-PromptTuning | 59.62%   | 53.73%    | 59.62% | 47.99%   |








# RQ4.2:
To assess the sensitivity of LLMs to data augmentation, we apply various augmentation techniques to six individual project datasets. These techniques include random synonym replacement, machine translation, random deletion, and random swapping as noise injection strategies. For each project, we generate five different augmented data groups along with the original dataset, resulting in a total of 30 data groups. We then use LLaMA models of different scales (1.1B, 7B, and 13B) to make predictions on these datasets, aiming to analyze the models' performance under different data augmentation conditions.

For each original requirement pair $r$, we generate four augmented variants $\{r_1, r_2, r_3, r_4\}$ using different augmentation techniques. Along with the original instance $r_0$, we obtain five versions $\{r_0, r_1, r_2, r_3, r_4\}$.

LLaMA models are  used to predict the traceability label $L(r_i) \in \{\text{traceable}, \text{non-traceable}\}$ for each version. A ``same label'' case is defined as one in which all five versions receive the same prediction:


We define the `SameLabel` function for a requirement $r$ as follows:

$$
\text{SameLabel}(r) = 
\begin{cases}
1, & \text{if } L(r_0) = L(r_1) = L(r_2) = L(r_3) = L(r_4) \\
0, & \text{otherwise}
\end{cases}
$$

We then compute the total number of such cases in the group:

$$
\text{TotalSameLabelCount}(TSLC) = \sum_{i=1}^{N} \text{SameLabel}(r^{(i)})
$$


where $N$ is the number of original requirement pairs in this group. This metric reflects whether the semantic changes introduced by augmentation are sufficient to alter the model's prediction, thus serving as an indirect measure of diversity introduced by the augmentation process.

| Model | Reslt of Original Dataset |    | Synonym Replacement |     | Machine Translation |     | Noising-based methods |     |     |     | TSLC |
|-------|---------------------------|----|---------------------|-----|---------------------|-----|-----------------------|-----|-----|-----|------|
|       |                           |    |                     |     |                     |     |                       | RD  |     | RWS |      |     |
|       |                           |    |                     | 0   | 1                   | 0   | 1                     | 0   | 1   | 0   | 1    |     |
| CM1   | TiniLlama                 | TP | 78                  | 42  | 36                  | 10  | 68                    | 56  | 22  | 15  | 63   | 6   |
|       |                           | FN | 283                 | 171 | 112                 | 38  | 245                   | 166 | 117 | 63  | 220  | 19  |
|       |                           | TN | 381                 | 215 | 166                 | 67  | 314                   | 239 | 142 | 73  | 308  | 3   |
|       |                           | FP | 148                 | 83  | 65                  | 23  | 125                   | 93  | 55  | 35  | 113  | 3   |
|       | 7B-Llama                  | TP | 34                  | 3   | 31                  | 8   | 26                    | 2   | 32  | 11  | 23   | 17  |
|       |                           | FN | 327                 | 20  | 307                 | 65  | 262                   | 13  | 314 | 82  | 245  | 0   |
|       |                           | TN | 445                 | 37  | 408                 | 115 | 330                   | 23  | 422 | 103 | 342  | 1   |
|       |                           | FP | 84                  | 9   | 75                  | 19  | 65                    | 4   | 80  | 19  | 65   | 45  |
|       | 13B-Llama                 | TP | 287                 | 254 | 33                  | 261 | 26                    | 91  | 196 | 25  | 262  | 2   |
|       |                           | FN | 74                  | 61  | 13                  | 65  | 9                     | 27  | 47  | 9   | 65   | 0   |
|       |                           | TN | 75                  | 60  | 15                  | 63  | 12                    | 28  | 47  | 10  | 65   | 5   |
|       |                           | FP | 454                 | 395 | 59                  | 401 | 53                    | 152 | 302 | 33  | 421  | 2   |
| Modis | TiniLlama                 | TP | 25                  | 0   | 25                  | 1   | 24                    | 2   | 23  | 2   | 23   | 21  |
|       |                           | FN | 0                   | 0   | 0                   | 0   | 0                     | 0   | 0   | 0   | 0    | 0   |
|       |                           | TN | 73                  | 0   | 73                  | 1   | 72                    | 0   | 73  | 7   | 66   | 66  |
|       |                           | FP | 0                   | 0   | 0                   | 0   | 0                     | 0   | 0   | 0   | 0    | 0   |
|       | 7B-Llama                  | TP | 10                  | 0   | 10                  | 0   | 10                    | 2   | 8   | 10  | 0    | 0   |
|       |                           | FN | 15                  | 0   | 15                  | 0   | 15                    | 1   | 14  | 13  | 2    | 0   |
|       |                           | TN | 50                  | 0   | 23                  | 3   | 20                    | 4   | 19  | 19  | 4    | 1   |
|       |                           | FP | 23                  | 1   | 49                  | 2   | 48                    | 3   | 47  | 48  | 2    | 1   |
|       | 13B-Llama                 | TP | 25                  | 0   | 25                  | 2   | 23                    | 0   | 25  | 1   | 24   | 22  |
|       |                           | FN | 0                   | 0   | 0                   | 0   | 0                     | 0   | 0   | 0   | 0    | 0   |
|       |                           | TN | 73                  | 0   | 73                  | 0   | 73                    | 1   | 72  | 1   | 72   | 72  |
|       |                           | FP | 0                   | 0   | 0                   | 0   | 0                     | 0   | 0   | 0   | 0    | 0   |
| GANNT | TiniLlama                 | TP | 37                  | 2   | 35                  | 8   | 29                    | 37  | 0   | 27  | 10   | 0   |
|       |                           | FN | 31                  | 0   | 31                  | 8   | 23                    | 0   | 31  | 27  | 4    | 0   |
|       |                           | TN | 71                  | 3   | 68                  | 21  | 50                    | 68  | 3   | 53  | 18   | 1   |
|       |                           | FP | 65                  | 3   | 62                  | 22  | 43                    | 63  | 2   | 43  | 22   | 0   |
|       | 7B-Llama                  | TP | 20                  | 7   | 13                  | 11  | 9                     | 20  | 0   | 0   | 20   | 0   |
|       |                           | FN | 48                  | 27  | 21                  | 20  | 28                    | 46  | 2   | 0   | 48   | 0   |
|       |                           | TN | 40                  | 19  | 21                  | 27  | 13                    | 39  | 1   | 1   | 39   | 0   |
|       |                           | FP | 96                  | 40  | 56                  | 50  | 46                    | 96  | 0   | 2   | 94   | 1   |
|       | 13B-Llama                 | TP | 27                  | 5   | 22                  | 8   | 19                    | 4   | 23  | 10  | 17   | 14  |
|       |                           | FN | 41                  | 26  | 15                  | 34  | 7                     | 33  | 8   | 32  | 9    | 17  |
|       |                           | TN | 63                  | 19  | 44                  | 23  | 40                    | 13  | 50  | 20  | 43   | 23  |
|       |                           | FP | 73                  | 55  | 18                  | 60  | 13                    | 59  | 14  | 56  | 17   | 34  |
| WARC  | TiniLlama                 | TP | 38                  | 25  | 13                  | 2   | 36                    | 5   | 33  | 3   | 35   | 13  |
|       |                           | FN | 98                  | 52  | 46                  | 4   | 94                    | 7   | 91  | 5   | 93   | 0   |
|       |                           | TN | 34                  | 23  | 11                  | 0   | 34                    | 1   | 33  | 2   | 32   | 11  |
|       |                           | FP | 97                  | 48  | 49                  | 13  | 84                    | 6   | 91  | 9   | 88   | 0   |
|       | 7B-Llama                  | TP | 20                  | 14  | 6                   | 17  | 3                     | 19  | 1   | 16  | 4    | 0   |
|       |                           | FN | 116                 | 29  | 87                  | 109 | 87                    | 111 | 5   | 43  | 73   | 9   |
|       |                           | TN | 23                  | 12  | 11                  | 13  | 10                    | 21  | 2   | 21  | 2    | 0   |
|       |                           | FP | 108                 | 22  | 86                  | 105 | 3                     | 101 | 7   | 47  | 61   | 6   |
|       | 13B-Llama                 | TP | 112                 | 8   | 104                 | 18  | 94                    | 8   | 104 | 16  | 96   | 70  |
|       |                           | FN | 24                  | 11  | 13                  | 11  | 13                    | 13  | 11  | 11  | 13   | 0   |
|       |                           | TN | 116                 | 13  | 103                 | 11  | 105                   | 9   | 107 | 9   | 107  | 82  |
|       |                           | FP | 15                  | 8   | 7                   | 4   | 11                    | 12  | 3   | 8   | 7    | 1   |
| CCHIT | TiniLlama                 | TP | 94                  | 0   | 92                  | 1   | 93                    | 5   | 89  | 10  | 84   | 79  |
|       |                           | FN | 7                   | 7   | 0                   | 1   | 6                     | 1   | 6   | 1   | 6    | 5   |
|       |                           | TN | 140                 | 5   | 135                 | 6   | 134                   | 7   | 133 | 12  | 128  | 118 |
|       |                           | FP | 11                  | 0   | 11                  | 0   | 11                    | 1   | 10  | 3   | 8    | 0   |
|       | 7B-Llama                  | TP | 1                   | 0   | 1                   | 1   | 0                     | 0   | 1   | 0   | 1    | 0   |
|       |                           | FN | 100                 | 94  | 6                   | 32  | 68                    | 93  | 7   | 18  | 82   | 3   |
|       |                           | TN | 0                   | 0   | 0                   | 0   | 0                     | 0   | 0   | 0   | 0    | 0   |
|       |                           | FP | 151                 | 139 | 12                  | 59  | 92                    | 138 | 11  | 28  | 123  | 9   |
|       | 13B-Llama                 | TP | 30                  | 9   | 21                  | 11  | 19                    | 9   | 21  | 8   | 22   | 10  |
|       |                           | FN | 71                  | 54  | 17                  | 62  | 9                     | 61  | 10  | 37  | 34   | 25  |
|       |                           | TN | 35                  | 8   | 27                  | 16  | 19                    | 7   | 28  | 15  | 20   | 9   |
|       |                           | FP | 116                 | 87  | 29                  | 95  | 21                    | 90  | 26  | 77  | 39   | 46  |
| IP    | TiniLlama                 | TP | 66                  | 0   | 66                  | 2   | 64                    | 1   | 65  | 2   | 64   | 61  |
|       |                           | FN | 0                   | 0   | 0                   | 0   | 0                     | 0   | 0   | 0   | 0    | 0   |
|       |                           | TN | 98                  | 1   | 97                  | 4   | 94                    | 0   | 98  | 1   | 97   | 92  |
|       |                           | FP | 1                   | 0   | 1                   | 0   | 1                     | 1   | 0   | 0   | 1    | 0   |
|       | 7B-Llama                  | TP | 22                  | 16  | 6                   | 9   | 13                    | 20  | 2   | 0   | 22   | 0   |
|       |                           | FN | 44                  | 32  | 12                  | 7   | 37                    | 34  | 10  | 1   | 43   | 0   |
|       |                           | TN | 40                  | 22  | 18                  | 15  | 25                    | 31  | 9   | 0   | 40   | 1   |
|       |                           | FP | 59                  | 41  | 18                  | 11  | 48                    | 45  | 14  | 1   | 58   | 0   |
|       | 13B-Llama                 | TP | 60                  | 12  | 48                  | 5   | 55                    | 3   | 57  | 8   | 52   | 37  |
|       |                           | FN | 6                   | 4   | 2                   | 1   | 5                     | 3   | 3   | 3   | 3    | 0   |
|       |                           | TN | 75                  | 15  | 60                  | 4   | 71                    | 3   | 72  | 16  | 59   | 50  |
|       |                           | FP | 24                  | 15  | 9                   | 6   | 18                    | 17  | 7   | 7   | 17   | 2   |


The experimental results are shown in Table, which presents the prediction performance of 1.1B,7B and 13B LLaMA models under different data augmentation strategies.
In more than 68% of the experiments, fewer than 10 samples per experiment yield identical predictions across the four data augmentation strategies and the original dataset. This suggests that models do not always treat augmented data as equivalent to the original, leading to notable variations in prediction outcomes.

In the Modis dataset, due to its small size, both the TinyLLaMA and 13B models exhibit cases where no false negatives (FN) or false positives (FP) are observed, meaning all instances are classified as having a traceability relationship. Similarly, in the CCHIT dataset, the 7B model predicts only one instance as traceable, while all other samples are categorized as non-traceable.

Further analysis shows that increasing the model size does not always improve its ability to distinguish between original and augmented data. For our first research question (RQ1), the 7B LLaMA model performs the best, yet it demonstrates the weakest ability to recognize augmented data. For instance, in the CM1 dataset, approximately half of the predictions in the TP (true positive) and FP (false positive) categories remain unchanged before and after augmentation, while for other datasets, this number is typically below 10%.

Additionally, in the 13B LLaMA model experiments, the prediction distribution for augmented data closely mirrors that of the original data. This model demonstrates the strongest ability to differentiate between augmented and original samples. However, even at this scale, the predictions before and after augmentation remain inconsistent in most cases. This suggests that while data augmentation increases dataset diversity, models do not always fully absorb the augmented variations. As a result, their ability to detect subtle differences remains limited.

Overall, our study demonstrates that data augmentation has a significant impact on the predictive performance of LLMs, and different models exhibit varying levels of adaptability to augmented data.  
Moreover, this suggests that, for most datasets, the three LLMs are not sufficiently robust when handling diverse or perturbed inputs, thereby underscoring the necessity of our fine-tuning approach.
